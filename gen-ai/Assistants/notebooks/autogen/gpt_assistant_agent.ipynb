{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Backed by Azure OpenAI Assistant API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPTAssistantAgent is a powerful component of the AutoGen framework, utilizing OpenAI's Assistant API to enhance agents with advanced capabilities. This agent enables the integration of multiple tools such as the Code Interpreter, File Search, and Function Calling, allowing for a highly customizable and dynamic interaction model.\n",
    "\n",
    "Version Requirements:\n",
    "\n",
    "- AutoGen: Version 0.2.27 or higher.\n",
    "- OpenAI: Version 1.21 or higher.\n",
    "\n",
    "Key Features of the GPTAssistantAgent:\n",
    "\n",
    "- Multi-Tool Mastery: Agents can leverage a combination of OpenAI's built-in tools, like Code Interpreter and File Search, alongside custom tools you create or integrate via Function Calling.\n",
    "\n",
    "- Streamlined Conversation Management: Benefit from persistent threads that automatically store message history and adjust based on the model's context length. This simplifies development by allowing you to focus on adding new messages rather than managing conversation flow.\n",
    "\n",
    "- File Access and Integration: Enable agents to access and utilize files in various formats. Files can be incorporated during agent creation or throughout conversations via threads. Additionally, agents can generate files (e.g., images, spreadsheets) and cite referenced files within their responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a OpenAI Assistant in Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(oai_agent) - model: gpt-4-1106-preview\n",
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen import UserProxyAgent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\", \n",
    "    max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "    {\n",
    "        \"model\": os.environ.get(\"OPENAI_GPT_DEPLOYMENT\", None),\n",
    "        \"api_key\": os.environ.get(\"OPENAI_KEY\", None),\n",
    "        \"base_url\": os.environ.get(\"OPENAI_URI\", None),\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": os.environ.get(\"OPENAI_VERSION\", None),\n",
    "    }\n",
    "],\n",
    "}\n",
    "assistant_config = {\n",
    "    # define the openai assistant behavior as you need\n",
    "}\n",
    "oai_agent = GPTAssistantAgent(\n",
    "    name=\"oai_agent\",\n",
    "    instructions=\"I'm an openai assistant running in autogen\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a test question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to oai_agent):\n",
      "\n",
      "Tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33moai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, how about this one:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Tell me a joke.', 'role': 'assistant'}, {'content': \"Sure, how about this one:\\n\\nWhy don't skeletons fight each other?\\n\\nThey don't have the guts.\\n\", 'role': 'user'}], summary=\"Sure, how about this one:\\n\\nWhy don't skeletons fight each other?\\n\\nThey don't have the guts.\\n\", cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(recipient=oai_agent,\n",
    "    message=\"Tell me a joke.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Use OpenAI Assistant Built-in Tools and Function Calling\n",
    "\n",
    "##### Code Interpreter\n",
    "\n",
    "The Code Interpreter empowers your agents to write and execute Python code in a secure environment provide by OpenAI. This unlocks several capabilities, including but not limited to:\n",
    "\n",
    "- Process data: Handle various data formats and manipulate data on the fly.\n",
    "- Generate outputs: Create new data files or even visualizations like graphs.\n",
    "\n",
    "Using the Code Interpreter with the following configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(code_oai_agent) - model: gpt-4-1106-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"code_interpreter\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "code_oai_agent = GPTAssistantAgent(\n",
    "    name=\"code_oai_agent\",\n",
    "    instructions=\"You are a code assistant tool that can run Python code\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to code_oai_agent):\n",
      "\n",
      "Run a Monty Hall problem simulation 10000 times, and tell me how often you win by switching doors.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcode_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "After running the Monty Hall problem simulation 10,000 times, you win approximately 6,610 times by switching doors, which corresponds to a winning probability of about 66.10%. This is consistent with the probability theory behind the Monty Hall problem, which states that by switching doors, the contestant has a 2/3 (or approximately 66.67%) chance of winning.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Run a Monty Hall problem simulation 10000 times, and tell me how often you win by switching doors.', 'role': 'assistant'}, {'content': 'After running the Monty Hall problem simulation 10,000 times, you win approximately 6,610 times by switching doors, which corresponds to a winning probability of about 66.10%. This is consistent with the probability theory behind the Monty Hall problem, which states that by switching doors, the contestant has a 2/3 (or approximately 66.67%) chance of winning.\\n', 'role': 'user'}], summary='After running the Monty Hall problem simulation 10,000 times, you win approximately 6,610 times by switching doors, which corresponds to a winning probability of about 66.10%. This is consistent with the probability theory behind the Monty Hall problem, which states that by switching doors, the contestant has a 2/3 (or approximately 66.67%) chance of winning.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(recipient=code_oai_agent,\n",
    "    message=\"Run a Monty Hall problem simulation 10000 times, and tell me how often you win by switching doors.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload files, you can employ two methods:\n",
    "\n",
    "Azure OpenAI Playground: Leverage the Azure OpenAI Playground, an interactive platform accessible at https://oai.azure.com, to upload your files and obtain the corresponding file IDs.\n",
    "\n",
    "Code-Based Uploading: Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 65610  100 65610    0     0  77083      0 --:--:-- --:--:-- --:--:-- 77083\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 83418  100 83418    0     0   281k      0 --:--:-- --:--:-- --:--:-- 3879k\n"
     ]
    }
   ],
   "source": [
    "# Get sample files\n",
    "\n",
    "!curl -L \"https://github.com/Azure-Samples/cognitive-services-sample-data-files/raw/master/openai/contoso_benefits_document_example.pdf\" > data/contoso_benefits_document_example.pdf\n",
    "!curl -L \"https://go.microsoft.com/fwlink/?LinkID=521962\" > data/financial_sample.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    base_url=os.environ.get(\"BASE_URL\"),\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    api_version=os.environ.get(\"OPENAI_VERSION\")\n",
    ")\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"data/financial_sample.xlsx\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(excel_oai_agent) - model: gpt-4-1106-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:Matching assistant found, using the first matching assistant: {'id': 'asst_sMaip1vu2bhhmQDW8ss39FbD', 'created_at': 1715956630, 'description': None, 'instructions': 'You are a code assistant tool that can run Python code', 'metadata': {}, 'model': 'gpt-4-1106-preview', 'name': 'excel_oai_agent', 'object': 'assistant', 'tools': [CodeInterpreterTool(type='code_interpreter')], 'tool_resources': ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['assistant-TuRN6MKhg7PleJKCKexs1vTu']), file_search=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to excel_oai_agent):\n",
      "\n",
      "What are the columns in the excel spreadsheet uploaded?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mexcel_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "The columns in the Excel spreadsheet are:\n",
      "\n",
      "1. Segment\n",
      "2. Country\n",
      "3. Product\n",
      "4. Discount Band\n",
      "5. Units Sold\n",
      "6. Manufacturing Price\n",
      "7. Sale Price\n",
      "8. Gross Sales\n",
      "9. Discounts\n",
      "10. Sales\n",
      "11. COGS\n",
      "12. Profit\n",
      "13. Date\n",
      "14. Month Number\n",
      "15. Month Name\n",
      "16. Year\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What are the columns in the excel spreadsheet uploaded?', 'role': 'assistant'}, {'content': 'The columns in the Excel spreadsheet are:\\n\\n1. Segment\\n2. Country\\n3. Product\\n4. Discount Band\\n5. Units Sold\\n6. Manufacturing Price\\n7. Sale Price\\n8. Gross Sales\\n9. Discounts\\n10. Sales\\n11. COGS\\n12. Profit\\n13. Date\\n14. Month Number\\n15. Month Name\\n16. Year\\n', 'role': 'user'}], summary='The columns in the Excel spreadsheet are:\\n\\n1. Segment\\n2. Country\\n3. Product\\n4. Discount Band\\n5. Units Sold\\n6. Manufacturing Price\\n7. Sale Price\\n8. Gross Sales\\n9. Discounts\\n10. Sales\\n11. COGS\\n12. Profit\\n13. Date\\n14. Month Number\\n15. Month Name\\n16. Year\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"code_interpreter\"}\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "excel_oai_agent = GPTAssistantAgent(\n",
    "    name=\"excel_oai_agent\",\n",
    "    instructions=\"You are a code assistant tool that can run Python code\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(recipient=excel_oai_agent,\n",
    "    message=\"What are the columns in the excel spreadsheet uploaded?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### File Search\n",
    "\n",
    "The File Search tool empowers your agents to tap into knowledge beyond its pre-trained model. This allows you to incorporate your own documents and data, such as product information or code files, into your agent's capabilities.\n",
    "\n",
    "Here's how to obtain the vector_store.id using two methods:\n",
    "\n",
    "OpenAI Playground: Leverage the Azure OpenAI Playground, an interactive platform accessible at https://oai.azure.com, to create a vector store, upload your files, and add it into your vector store. Once complete, you'll be able to retrieve the associated vector_store.id.\n",
    "\n",
    "Code-Based Uploading:Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store created: vs_FFMAaffcy5bgIGagoAeoXMtQ\n",
      "File batch status: completed\n",
      "Uploaded file count: 1\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    base_url=os.environ.get(\"BASE_URL\"),\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    api_version=os.environ.get(\"OPENAI_VERSION\")\n",
    ")\n",
    "\n",
    "# Step 1: Create a Vector Store\n",
    "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
    "print(\"Vector Store created:\", vector_store.id)  # This is your vector_store.id\n",
    "\n",
    "# Step 2: Prepare Files for Upload\n",
    "file_paths = [\"./data/contoso_benefits_document_example.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Step 3: Upload Files and Add to Vector Store (with status polling)\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# Step 4: Verify Completion (Optional)\n",
    "print(\"File batch status:\", file_batch.status)\n",
    "print(\"Uploaded file count:\", file_batch.file_counts.completed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(files_oai_agent) - model: gpt-4-1106-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:Matching assistant found, using the first matching assistant: {'id': 'asst_77w6GdlvzdnVln26AIsTPP7J', 'created_at': 1715956983, 'description': None, 'instructions': 'You are a files search assistant tool', 'metadata': {}, 'model': 'gpt-4-1106-preview', 'name': 'files_oai_agent', 'object': 'assistant', 'tools': [FileSearchTool(type='file_search')], 'tool_resources': ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_fcUfwOgzdnAu6sPA7sN0wBf4']))}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to files_oai_agent):\n",
      "\n",
      "Does Contoso benefits cover dental care?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mfiles_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Yes, Contoso benefits do cover dental care. According to the Contoso electronics plan and benefit packages, there are two plans available that provide dental care:\n",
      "\n",
      "1. **Northwind Health Plus**: This comprehensive plan offers coverage for dental services which includes dental exams, cleanings, and fillings.\n",
      "2. **Northwind Standard**: This basic plan provides coverage for medical, vision, and dental services, although it only specifies coverage for vision exams and glasses, it does not explicitly state the extent of dental services covered.\n",
      "\n",
      "Therefore, if you are considering dental coverage, the Northwind Health Plus might be the more suitable option for comprehensive dental care【0†contoso_benefits_document_example.pdf】.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Does Contoso benefits cover dental care?', 'role': 'assistant'}, {'content': 'Yes, Contoso benefits do cover dental care. According to the Contoso electronics plan and benefit packages, there are two plans available that provide dental care:\\n\\n1. **Northwind Health Plus**: This comprehensive plan offers coverage for dental services which includes dental exams, cleanings, and fillings.\\n2. **Northwind Standard**: This basic plan provides coverage for medical, vision, and dental services, although it only specifies coverage for vision exams and glasses, it does not explicitly state the extent of dental services covered.\\n\\nTherefore, if you are considering dental coverage, the Northwind Health Plus might be the more suitable option for comprehensive dental care【0†contoso_benefits_document_example.pdf】.\\n', 'role': 'user'}], summary='Yes, Contoso benefits do cover dental care. According to the Contoso electronics plan and benefit packages, there are two plans available that provide dental care:\\n\\n1. **Northwind Health Plus**: This comprehensive plan offers coverage for dental services which includes dental exams, cleanings, and fillings.\\n2. **Northwind Standard**: This basic plan provides coverage for medical, vision, and dental services, although it only specifies coverage for vision exams and glasses, it does not explicitly state the extent of dental services covered.\\n\\nTherefore, if you are considering dental coverage, the Northwind Health Plus might be the more suitable option for comprehensive dental care【0†contoso_benefits_document_example.pdf】.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"retrieval\"}\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "files_oai_agent = GPTAssistantAgent(\n",
    "    name=\"files_oai_agent\",\n",
    "    instructions=\"You are a files search assistant tool\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(recipient=files_oai_agent,\n",
    "    message=\"Does Contoso benefits cover dental care?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Function Calling empowers you to extend the capabilities of your agents with your pre-defined functionalities, which allows you to describe custom functions to the Assistant, enabling intelligent function selection and argument generation.\n",
    "\n",
    "Using the Function calling with the following configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(functions_oai_agent) - model: gpt-4-1106-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:Matching assistant found, using the first matching assistant: {'id': 'asst_ZexC6Wjj5Z4rmc9aAVxiXhrq', 'created_at': 1715957344, 'description': None, 'instructions': 'You are a weather assistant', 'metadata': {}, 'model': 'gpt-4-1106-preview', 'name': 'functions_oai_agent', 'object': 'assistant', 'tools': [FunctionTool(function=FunctionDefinition(name='get_current_weather', description='Returns the current weather data for a specified location.', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'location'}}, 'required': ['location']}), type='function')], 'tool_resources': ToolResources(code_interpreter=None, file_search=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to functions_oai_agent):\n",
      "\n",
      "What's the weather like in Redmond, WA?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_current_weather...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(get_current_weather, Success: True) : {'location': 'Redmond, WA', 'temperature': 22.5, 'description': 'Partly cloudy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mfunctions_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's the weather like in Redmond, WA?\", 'role': 'assistant'}, {'content': 'The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\\n', 'role': 'user'}], summary='The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.function_utils import get_function_schema\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "def get_current_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the current weather for a specified location.\n",
    "\n",
    "    Args:\n",
    "    location (str): The location to get the weather for.\n",
    "\n",
    "    Returns:\n",
    "    Union[str, dict]: A dictionary with weather details..\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulated response\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 22.5,\n",
    "        \"description\": \"Partly cloudy\"\n",
    "    }\n",
    "\n",
    "api_schema = get_function_schema(\n",
    "    get_current_weather,\n",
    "    name=get_current_weather.__name__,\n",
    "    description=\"Returns the current weather data for a specified location.\"\n",
    ")\n",
    "\n",
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        api_schema\n",
    "    ],\n",
    "}\n",
    "\n",
    "functions_oai_agent = GPTAssistantAgent(\n",
    "    name=\"functions_oai_agent\",\n",
    "    instructions=\"You are a weather assistant\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    "    function_map={\n",
    "        \"get_current_weather\": get_current_weather\n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(recipient=functions_oai_agent,\n",
    "    message=\"What's the weather like in Redmond, WA?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
